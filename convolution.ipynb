{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSG45gqPLHZazCmvm3au8/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dipak22/Case-Studies/blob/master/convolution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import necessary classes and functions"
      ],
      "metadata": {
        "id": "b29cx8uvqoRP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PGO7X-t1qlxR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### create a dummy image and check out the changes after applying convolutions"
      ],
      "metadata": {
        "id": "DEXI0CusrLJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(3,128,128)\n",
        "\n",
        "# Baseline convolution\n",
        "conv1 = nn.Conv2d(in_channels=3,\n",
        "                  out_channels=3,\n",
        "                  kernel_size=3,\n",
        "                  stride = 1,\n",
        "                  padding=0)\n",
        "\n",
        "#COnvolution with larger kernel\n",
        "conv2 = nn.Conv2d(in_channels=3,\n",
        "                  out_channels=3,\n",
        "                  kernel_size=7,\n",
        "                  stride=1,\n",
        "                  padding=0\n",
        "                  )\n",
        "\n",
        "#convolution with larger stride\n",
        "conv3 = nn.Conv2d(in_channels=3,\n",
        "                  out_channels=3,\n",
        "                  kernel_size=3,\n",
        "                  stride=3,\n",
        "                  padding=0)\n",
        "\n",
        "#convolution with larger padding\n",
        "conv4 = nn.Conv2d(in_channels=3,\n",
        "                  out_channels=3,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=2)\n",
        "\n",
        "#convoolution with larger output channels\n",
        "conv5 = nn.Conv2d(in_channels=3,\n",
        "                  out_channels=64,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=0)\n",
        "\n",
        "conv1_out = conv1(rand)\n",
        "conv2_out = conv2(rand)\n",
        "conv3_out = conv3(rand)\n",
        "conv4_out = conv4(rand)\n",
        "conv5_out = conv5(rand)\n",
        "\n",
        "print(f\"Baseline output: {conv1_out.shape}\")\n",
        "print(f\"Larger kernel output: {conv2_out.shape}\")\n",
        "print(f\"Larger stride output: {conv3_out.shape}\")\n",
        "print(f\"Larger padding output: {conv4_out.shape}\")\n",
        "print(f\"More output channels output: {conv5_out.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHfLT0qKrFU0",
        "outputId": "f4f0b274-4a81-45ff-9b2e-7d98d1e619e4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline output: torch.Size([3, 126, 126])\n",
            "Larger kernel output: torch.Size([3, 122, 122])\n",
            "Larger stride output: torch.Size([3, 42, 42])\n",
            "Larger padding output: torch.Size([3, 130, 130])\n",
            "More output channels output: torch.Size([64, 126, 126])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.rand(32,3,128,128)\n",
        "patches = nn.functional.unfold(x, kernel_size=3,stride=1, padding=0)\n",
        "_, coef, num_patches = patches.shape\n",
        "print(patches.shape)\n",
        "patches = patches.transpose(1,2).reshape(-1,coef )\n",
        "print(patches.shape)\n",
        "ln = nn.Linear(3 * 3 * 3, 64, bias = True)\n",
        "conv_output = ln(patches)\n",
        "print(conv_output.shape)\n",
        "#reshape to batch, out, num_patches\n",
        "conv_output = conv_output.view(32,64, -1)\n",
        "print(conv_output.shape)\n",
        "out_height = (128 + 2 *0 - 3)//1 +1\n",
        "out_width = (128 + 2 *0 - 3)//1 +1\n",
        "output  = conv_output.view(32,64,out_height, out_width)\n",
        "print(output.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvjHQyt1wRIr",
        "outputId": "7f279e77-6028-4669-aae9-28c88db3363c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 27, 15876])\n",
            "torch.Size([508032, 27])\n",
            "torch.Size([508032, 64])\n",
            "torch.Size([32, 64, 15876])\n",
            "torch.Size([32, 64, 126, 126])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing convolution using `nn.Unfold`"
      ],
      "metadata": {
        "id": "LTlnU_3tujiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyConv2d(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride =1, padding = 0):\n",
        "    super(MyConv2d, self).__init__()\n",
        "\n",
        "    self.kernel_size = kernel_size\n",
        "    self.stride = stride\n",
        "    self.padding = padding\n",
        "    self.in_channels = in_channels\n",
        "    self.out_channels = out_channels\n",
        "\n",
        "    #Define the weights of the convolution as a linear layer\n",
        "    self.linear = nn.Linear(in_channels * kernel_size * kernel_size, out_channels,bias = True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    batch_size, channels, height, width = x.shape\n",
        "\n",
        "    #Ensure input channels match\n",
        "    assert self.in_channels == channels, \" Input channels mismatch\"\n",
        "\n",
        "    #Unfold the input into patches\n",
        "    #shape; batchsize, in_channels * kernel_size * kernel_size, num_patches\n",
        "    patches = nn.functional.unfold(x,\n",
        "                                   kernel_size=self.kernel_size,\n",
        "                                   stride = self.stride,\n",
        "                                   padding=self.padding)\n",
        "    # stroe kernel coefficients and num_patches\n",
        "    _, num_kernel_coefficients, num_patches = patches.shape\n",
        "    #transpose the shape to batch_size * num_patches, in_channels * kernel_size * kernel_size\n",
        "    patches = patches.transpose(1,2).reshape(-1, num_kernel_coefficients)\n",
        "\n",
        "    #Apply linear layer to perform convolution\n",
        "    conv_output = self.linear(patches) #shape batch_size * num_patches , out_channels\n",
        "\n",
        "    # reshape to batch_size, out_channels, num_patches\n",
        "    conv_output = conv_output.view(batch_size,self.out_channels, -1)\n",
        "    output_height = (height + 2*self.padding - self.kernel_size )//self.stride + 1\n",
        "    output_width = (width + 2*self.padding - self.kernel_size )//self.stride + 1\n",
        "\n",
        "    output = conv_output.view(batch_size, self.out_channels, output_height, output_width)\n",
        "\n",
        "    return output\n",
        ""
      ],
      "metadata": {
        "id": "i9i_Jikgs_8s"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "myconv = MyConv2d(in_channels=3,\n",
        "                  out_channels=64,\n",
        "                  kernel_size=7,\n",
        "                  stride=1,\n",
        "                  padding=0)\n",
        "torchconv = nn.Conv2d(in_channels=3,\n",
        "                      out_channels=64,\n",
        "                      kernel_size=7,\n",
        "                      padding=0,\n",
        "                      stride=1)\n",
        "rand = torch.randn(4,3,128,128)\n",
        "\n",
        "myconv_out = myconv(rand)\n",
        "torchconv_out = torchconv(rand)\n",
        "\n",
        "print(\"Output of my convolution: \", myconv_out.shape)\n",
        "print(\"Output of pytorch convolution: \", torchconv_out.shape )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXCit6Xa4gpA",
        "outputId": "cddfde30-d62c-4b92-b8bc-735277b98e6c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output of my convolution:  torch.Size([4, 64, 122, 122])\n",
            "Output of pytorch convolution:  torch.Size([4, 64, 122, 122])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Average pooling"
      ],
      "metadata": {
        "id": "ynLT2rjZ6wFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a rand image\n",
        "rand = torch.rand(3,128,128)\n",
        "avgpool = nn.AvgPool2d(kernel_size=3)\n",
        "avgpool_2 = nn.AvgPool2d(kernel_size=3, stride = 2)\n",
        "\n",
        "out_1 = avgpool(rand)\n",
        "out_2 = avgpool_2(rand)\n",
        "print(\"Basic avg pool, kernel_size == stride\", out_1.shape)\n",
        "print(\" smaller stride =2\", out_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70DfJbmu6vcx",
        "outputId": "97b1ebec-178e-4e34-b573-e42344712bae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basic avg pool, kernel_size == stride torch.Size([3, 42, 42])\n",
            " smaller stride =2 torch.Size([3, 63, 63])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Adaptive pooling\n",
        "we set the output size we want, it figures out the kernel and stride for us."
      ],
      "metadata": {
        "id": "ZwwGU55ZFsTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rand = torch.rand(3,128,128)\n",
        "\n",
        "adaptivepool_1 = nn.AdaptiveAvgPool2d((64,64))\n",
        "adaptivepool_2 = nn.AdaptiveAvgPool2d((64,48))\n",
        "\n",
        "out_1 = adaptivepool_1(rand)\n",
        "out_2 = adaptivepool_2(rand)\n",
        "print(\" Avg pol 1: \",out_1.shape)\n",
        "print(\"Avg pool 2: \", out_2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKlkIfdT5l65",
        "outputId": "5c60542d-66cd-433f-8d01-8d9f4c580cd3"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Avg pol 1:  torch.Size([3, 64, 64])\n",
            "Avg pool 2:  torch.Size([3, 64, 48])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lt7fMNFlGLrl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}